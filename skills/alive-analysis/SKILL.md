# alive-analysis Skill

> Data analysis workflow kit based on the ALIVE loop.
> Provides structured analysis methodology for data analysts and non-analyst roles.

---

## Overview

alive-analysis helps structure data analysis work using the **ALIVE loop**:
**Ask â†’ Look â†’ Investigate â†’ Voice â†’ Evolve**

It serves two personas:
- **Data analysts**: Deep, systematic analysis with full ALIVE flow
- **Non-analyst roles** (PM, engineers, marketers): Quick analysis with guided framework

---

## ALIVE Loop Reference

### Stage 1: ASK (â“)
**Core question**: What do we want to know?

Purpose:
- Define the problem clearly
- Set success criteria
- State assumptions and scope
- Identify data sources

Common mistakes to prevent:
- Starting analysis without a clear question
- Scope creep â€” trying to answer everything at once
- Not confirming the requester's actual goal (vs stated goal)

### Stage 2: LOOK (ğŸ‘€)
**Core question**: What does the data show?

Purpose:
- Review data quality (missing values, outliers, date ranges)
- Validate sampling approach
- Note initial observations before deep analysis

Common mistakes to prevent:
- Using unnecessarily large datasets
- Re-verifying already confirmed data
- Skipping data quality checks

### Stage 3: INVESTIGATE (ğŸ”)
**Core question**: Why is it happening?

Purpose:
- Form and test hypotheses
- Apply analytical methods
- Document results with evidence
- Ensure reproducibility

Common mistakes to prevent:
- Confirmation bias â€” only looking for supporting evidence
- Not recording queries/code for reproduction
- Over-complicating visualizations

### Stage 4: VOICE (ğŸ“¢)
**Core question**: How do we communicate this?

Purpose:
- Summarize conclusions for different audiences
- Provide actionable recommendations
- Document data sources and limitations

Common mistakes to prevent:
- Burying the lead â€” not stating the conclusion first
- Using jargon with non-technical audiences
- Not answering the original question

### Stage 5: EVOLVE (ğŸŒ±)
**Core question**: What should we ask next?

Purpose:
- Reflect on the analysis process
- Identify unanswered questions
- Propose follow-up analyses
- Find automation opportunities

Common mistakes to prevent:
- Treating the analysis as "done" without reflection
- Not capturing follow-up ideas while they're fresh

---

## Checklist Templates

### Default: ASK Checklist
```markdown
## Checklist â€” ASK
- [ ] ğŸŸ¢/ğŸ”´ Have you accurately identified the requester's goal?
- [ ] ğŸŸ¢/ğŸ”´ Have you secured relevant domain knowledge?
- [ ] ğŸŸ¢/ğŸ”´ Have you created an analysis plan that fits the timeline?
- [ ] ğŸŸ¢/ğŸ”´ Have you estimated time per scope area?
- [ ] ğŸŸ¢/ğŸ”´ Have you confirmed the data specification?
- [ ] ğŸŸ¢/ğŸ”´ Have you considered a confusion matrix (if applicable)?
- [ ] ğŸŸ¢/ğŸ”´ Have you considered appropriate sample size?
```

### Default: LOOK Checklist
```markdown
## Checklist â€” LOOK
- [ ] ğŸŸ¢/ğŸ”´ Are you avoiding unnecessarily large datasets?
- [ ] ğŸŸ¢/ğŸ”´ Are you not wasting time re-verifying confirmed findings?
- [ ] ğŸŸ¢/ğŸ”´ Is the sampling method appropriate?
- [ ] ğŸŸ¢/ğŸ”´ Have you checked for data errors (outliers, missing values)?
- [ ] ğŸŸ¢/ğŸ”´ Have you considered edge cases (specific IDs, exceptions)?
- [ ] ğŸŸ¢/ğŸ”´ Are you only performing analysis needed for the problem?
- [ ] ğŸŸ¢/ğŸ”´ Before long-running tasks, have you verified the method is optimal?
```

### Default: INVESTIGATE Checklist
```markdown
## Checklist â€” INVESTIGATE
- [ ] ğŸŸ¢/ğŸ”´ Have you exchanged feedback with a colleague?
- [ ] ğŸŸ¢/ğŸ”´ Have you clearly handled outliers/anomalies?
- [ ] ğŸŸ¢/ğŸ”´ Have you visually verified the results yourself?
- [ ] ğŸŸ¢/ğŸ”´ Are charts easy to understand?
- [ ] ğŸŸ¢/ğŸ”´ Have you removed unnecessary visualizations/complexity?
- [ ] ğŸŸ¢/ğŸ”´ Can the results be reproduced? (queries/code recorded)
```

### Default: VOICE Checklist
```markdown
## Checklist â€” VOICE
- [ ] ğŸŸ¢/ğŸ”´ Have you accurately answered the requester's question?
- [ ] ğŸŸ¢/ğŸ”´ Have you reviewed results with a colleague?
- [ ] ğŸŸ¢/ğŸ”´ Have you validated explanations through simulation?
- [ ] ğŸŸ¢/ğŸ”´ Have you documented data sources for re-verification?
```

### Default: EVOLVE Checklist
```markdown
## Checklist â€” EVOLVE
- [ ] ğŸŸ¢/ğŸ”´ Are there perspectives missed in this analysis?
- [ ] ğŸŸ¢/ğŸ”´ Are follow-up questions specifically defined?
- [ ] ğŸŸ¢/ğŸ”´ Are there parts to automate or schedule?
- [ ] ğŸŸ¢/ğŸ”´ Have you summarized the key insight in one sentence?
```

---

## Quick Analysis Checklist (Abbreviated)

For Quick mode, use only these 3 items:
```markdown
Check: ğŸŸ¢ Proceed / ğŸ”´ Stop
- [ ] Is the purpose of the question clear?
- [ ] Is the data source appropriate?
- [ ] Does the conclusion answer the question?
```

---

## ID Format

- **Full**: `F-{YYYY}-{MMDD}-{sequence}` (e.g., `F-2026-0210-001`)
- **Quick**: `Q-{YYYY}-{MMDD}-{sequence}` (e.g., `Q-2026-0210-002`)
- Sequence resets daily, starts at 001

---

## Stage Icons

```
â“ ASK â†’ ğŸ‘€ LOOK â†’ ğŸ” INVESTIGATE â†’ ğŸ“¢ VOICE â†’ ğŸŒ± EVOLVE
âœ… Archived | â³ Pending | ğŸŸ¡ In Progress
```

---

## File Naming Conventions

- Full analysis folder: `{ID}_{title-slug}/` (e.g., `F-2026-0210-001_dau-drop-investigation/`)
- Quick analysis file: `quick_{ID}_{title-slug}.md`
- Title slug: lowercase, hyphens, no special characters
- Stage files: `01_ask.md`, `02_look.md`, `03_investigate.md`, `04_voice.md`, `05_evolve.md`

---

## Archive Rules

1. Archive after VOICE + EVOLVE are complete
2. Generate `summary.md` with key insight, findings, and reproduction info
3. Move from `analyses/active/` to `analyses/archive/{YYYY-MM}/`
4. Update status.md (remove from Active, add to Recently Archived)
5. Keep max 5 entries in Recently Archived

---

## Language Support

- Document language is set in `.analysis/config.md`
- Checklists, templates, and status messages follow the configured language
- Default: Korean (í•œêµ­ì–´)
- Supported: Korean, English, Japanese

---

## Interaction Guidelines

**CRITICAL: alive-analysis is a conversational workflow.**
Do NOT auto-fill analysis content. Each stage must be a dialogue with the user.
The AI is a guide and co-analyst, not an auto-generator.

### Core Principles

1. **Ask, don't assume** â€” Every stage starts with questions to the user.
2. **One stage at a time** â€” Never skip ahead. Complete the current stage through conversation before moving on.
3. **User writes the insight, AI structures it** â€” The user provides domain knowledge and judgment. AI helps organize, challenge, and document.
4. **Pause at checklists** â€” Before advancing, walk through the checklist WITH the user. Each item is a conversation, not a checkbox to auto-fill.

### Stage-by-Stage Conversation Flow

#### ASK Stage
```
AI: "What question are you trying to answer?"
User: (describes the problem)
AI: "Who requested this? What's the deadline?"
User: (provides context)
AI: "Let me clarify the scope â€” is X in or out of scope?"
User: (confirms)
AI: â†’ Writes 01_ask.md with user's answers
AI: "Let's check before moving on:"
    - "Do we clearly understand what the requester wants? ğŸŸ¢/ğŸ”´"
    - "Do we know where the data lives? ğŸŸ¢/ğŸ”´"
AI: "Ready to move to LOOK? Or anything to add?"
```

#### LOOK Stage
```
AI: "What data sources will you use?"
User: (lists sources)
AI: "Any known data quality issues? Missing values, date range gaps?"
User: (describes)
AI: "How large is the dataset? Do we need sampling?"
User: (answers)
AI: â†’ Updates 02_look.md
AI: "Checklist review:"
    - "Are we using only necessary data? ğŸŸ¢/ğŸ”´"
    - "Have we checked for outliers? ğŸŸ¢/ğŸ”´"
```

#### INVESTIGATE Stage
```
AI: "What's your hypothesis for why this is happening?"
User: (states hypothesis)
AI: "What method will you use to test this?"
User: (describes approach)
AI: "What did you find?"
User: (shares results)
AI: "How confident are you? Any alternative explanations?"
User: (discusses)
AI: â†’ Updates 03_investigate.md
AI: "Can someone else reproduce this? Is the query/code saved?"
```

#### VOICE Stage
```
AI: "If you had to explain this in one sentence to leadership, what would you say?"
User: (gives summary)
AI: "Who needs to hear this? What action should they take?"
User: (identifies audience + recommendations)
AI: "Any caveats or limitations they should know about?"
User: (lists limitations)
AI: â†’ Updates 04_voice.md
```

#### EVOLVE Stage
```
AI: "What questions came up during this analysis that we didn't answer?"
User: (lists open questions)
AI: "Any part of this could be automated for next time?"
User: (considers)
AI: "One sentence â€” what's the single most important takeaway?"
User: (provides insight)
AI: â†’ Updates 05_evolve.md
AI: "Ready to archive? Or want to revisit any stage?"
```

### Quick Mode Conversation

For Quick, the same dialogue happens but compressed:
```
AI: "What's the question? (ASK)"
User: "Why did signups drop yesterday?"
AI: "Where will you look? (LOOK)"
User: "GA4 events and server logs"
AI: "What did you find? (INVESTIGATE)"
User: "Mobile auth API was down 14-17h"
AI: "What's the conclusion? (VOICE)"
User: "SKT API maintenance caused mobile signup failures"
AI: "Any follow-up needed? (EVOLVE)"
User: "Yeah, should we add email auth as fallback?"
AI: â†’ Writes the complete Quick file
AI: "Checklist: purpose clear? âœ… data source OK? âœ… conclusion answers question? âœ…"
AI: "Archive this, or keep it active?"
```

### What NOT to do

- âŒ Generate analysis content without asking the user
- âŒ Skip stages or combine multiple stages at once
- âŒ Auto-check all checklist items without discussion
- âŒ Move to the next stage without user confirmation
- âŒ Make assumptions about data, methods, or conclusions
